{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyN1vGR/JHs9ElUKixKEBF0v",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AinaRB/2022_TempReconstructionSaoPaulo_EO_ML/blob/main/DataPreparation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define environment"
      ],
      "metadata": {
        "id": "HUsMnBgaug2Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# insert your desired path to work on\n",
        "import os\n",
        "from os.path import join\n",
        "project_path = \"S:\\Projects\\AinaRB_ClimateHealth\\Part2_Spatial\\Obj2_TempModelling\"\n",
        "project_path"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "1YrXLqMgv8l-",
        "outputId": "95e7e263-c433-4746-fe60-d457b9db1611"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'S:/Projects/AinaRB_ClimateHealth/Part2_Spatial/Obj2_TempModelling'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Link code folder to python execution path\n",
        "import sys\n",
        "sys.path.append(join(project_path, 'code'))"
      ],
      "metadata": {
        "id": "a_DVGKLKyrNV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Detect changes in external code and to automatically update it without restarting the runtime.\n",
        "%load_ext autoreload\n",
        "%autoreload 2"
      ],
      "metadata": {
        "id": "fbmNPLmkysl9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Define plotting settings\n",
        "import matplotlib\n",
        "font = {'family':'Arial', 'size':'15', 'weight':'normal'}\n",
        "\n",
        "matplotlib.rc('font', **font)"
      ],
      "metadata": {
        "id": "wSowQLldyESc"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define folder structure \n",
        "config = {\n",
        "    'main': 'Brazil',\n",
        "    'output': join(project_path, \"code\", \"models\"),\n",
        "    'metrics': join(project_path, \"code\", \"metrics\")\n",
        "}\n",
        "\n",
        "# List comprehension for the folder structure code\n",
        "[os.makedirs(val, exist_ok=True) for key, val in config.items()]"
      ],
      "metadata": {
        "id": "Thoc8ZtEyb56"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Import libraries\n",
        "#import utils\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import scipy.stats as st\n",
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from datetime import datetime\n",
        "from glob import glob\n",
        "#from config import DEP_NAMES, GROUPED_VARS, DATA_REDUCER_SETTINGS, DATA_PROCESSING_SETTINGS"
      ],
      "metadata": {
        "id": "iiagRD7nzkrY"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import data and inspect"
      ],
      "metadata": {
        "id": "sl7z08toumaa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since we are working with Google Collab, we first need to import the libraries to browse the file we want to import from our local directory. Once that is selected, then we can read it as a panda dataframe. "
      ],
      "metadata": {
        "id": "fTA8f8Py5f9P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Import the data\n",
        "from google.colab import files\n",
        "uploaded = files.upload()\n"
      ],
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "p77GqlbKz2kP",
        "outputId": "411117e9-cffc-4b38-d90e-cda81dd4c6c9"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-0fed8e04-6236-4775-8b9f-9a78b95d5901\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-0fed8e04-6236-4775-8b9f-9a78b95d5901\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving data2018_modelinput.csv to data2018_modelinput.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import io\n",
        "df=pd.read_csv(io.BytesIO(uploaded['data2018_modelinput.csv']))"
      ],
      "metadata": {
        "id": "DKp_NkFt5Cns"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Below, we explore the dataframe"
      ],
      "metadata": {
        "id": "GPdO9GTF5q7C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 236
        },
        "id": "OEzmFTOf5tNW",
        "outputId": "9c50859b-3d64-4c14-87fc-44adcb0563a7"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  station_code        date    lat    lon        source  year  month  day.x  \\\n",
              "0      1000840  2018-01-01 -23.63 -46.58  cgs_stations  2018      1      1   \n",
              "1      1000840  2018-01-02 -23.63 -46.58  cgs_stations  2018      1      2   \n",
              "2      1000840  2018-01-03 -23.63 -46.58  cgs_stations  2018      1      3   \n",
              "3      1000840  2018-01-04 -23.63 -46.58  cgs_stations  2018      1      4   \n",
              "4      1000840  2018-01-05 -23.63 -46.58  cgs_stations  2018      1      5   \n",
              "\n",
              "   temp_mean75  doy  ...  elevation_500m  slope_500m  ImprSuf_SP  \\\n",
              "0    24.326035    1  ...      743.772278    0.684851           2   \n",
              "1    24.526826    2  ...      743.772278    0.684851           2   \n",
              "2    21.867257    3  ...      743.772278    0.684851           2   \n",
              "3    21.616583    4  ...      743.772278    0.684851           2   \n",
              "4    21.909021    5  ...      743.772278    0.684851           2   \n",
              "\n",
              "   dist_to_coast  ESArivers       popdens      ndvi         bsa   sza  \\\n",
              "0      45.233009   1.509531  10224.246094  0.173255  141.360397  1668   \n",
              "1      45.233009   1.509531  10224.246094  0.173255  141.360397  1668   \n",
              "2      45.233009   1.509531  10224.246094  0.173255  141.360397  1668   \n",
              "3      45.233009   1.509531  10224.246094  0.173255  141.360397  1668   \n",
              "4      45.233009   1.509531  10224.246094  0.173255  141.360397  1668   \n",
              "\n",
              "         lst  \n",
              "0  29.140158  \n",
              "1  29.160706  \n",
              "2  28.434814  \n",
              "3  28.685966  \n",
              "4  28.808559  \n",
              "\n",
              "[5 rows x 23 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-bc04d77a-abed-4004-a387-8f90289f2066\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>station_code</th>\n",
              "      <th>date</th>\n",
              "      <th>lat</th>\n",
              "      <th>lon</th>\n",
              "      <th>source</th>\n",
              "      <th>year</th>\n",
              "      <th>month</th>\n",
              "      <th>day.x</th>\n",
              "      <th>temp_mean75</th>\n",
              "      <th>doy</th>\n",
              "      <th>...</th>\n",
              "      <th>elevation_500m</th>\n",
              "      <th>slope_500m</th>\n",
              "      <th>ImprSuf_SP</th>\n",
              "      <th>dist_to_coast</th>\n",
              "      <th>ESArivers</th>\n",
              "      <th>popdens</th>\n",
              "      <th>ndvi</th>\n",
              "      <th>bsa</th>\n",
              "      <th>sza</th>\n",
              "      <th>lst</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1000840</td>\n",
              "      <td>2018-01-01</td>\n",
              "      <td>-23.63</td>\n",
              "      <td>-46.58</td>\n",
              "      <td>cgs_stations</td>\n",
              "      <td>2018</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>24.326035</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>743.772278</td>\n",
              "      <td>0.684851</td>\n",
              "      <td>2</td>\n",
              "      <td>45.233009</td>\n",
              "      <td>1.509531</td>\n",
              "      <td>10224.246094</td>\n",
              "      <td>0.173255</td>\n",
              "      <td>141.360397</td>\n",
              "      <td>1668</td>\n",
              "      <td>29.140158</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1000840</td>\n",
              "      <td>2018-01-02</td>\n",
              "      <td>-23.63</td>\n",
              "      <td>-46.58</td>\n",
              "      <td>cgs_stations</td>\n",
              "      <td>2018</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>24.526826</td>\n",
              "      <td>2</td>\n",
              "      <td>...</td>\n",
              "      <td>743.772278</td>\n",
              "      <td>0.684851</td>\n",
              "      <td>2</td>\n",
              "      <td>45.233009</td>\n",
              "      <td>1.509531</td>\n",
              "      <td>10224.246094</td>\n",
              "      <td>0.173255</td>\n",
              "      <td>141.360397</td>\n",
              "      <td>1668</td>\n",
              "      <td>29.160706</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1000840</td>\n",
              "      <td>2018-01-03</td>\n",
              "      <td>-23.63</td>\n",
              "      <td>-46.58</td>\n",
              "      <td>cgs_stations</td>\n",
              "      <td>2018</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>21.867257</td>\n",
              "      <td>3</td>\n",
              "      <td>...</td>\n",
              "      <td>743.772278</td>\n",
              "      <td>0.684851</td>\n",
              "      <td>2</td>\n",
              "      <td>45.233009</td>\n",
              "      <td>1.509531</td>\n",
              "      <td>10224.246094</td>\n",
              "      <td>0.173255</td>\n",
              "      <td>141.360397</td>\n",
              "      <td>1668</td>\n",
              "      <td>28.434814</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1000840</td>\n",
              "      <td>2018-01-04</td>\n",
              "      <td>-23.63</td>\n",
              "      <td>-46.58</td>\n",
              "      <td>cgs_stations</td>\n",
              "      <td>2018</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>21.616583</td>\n",
              "      <td>4</td>\n",
              "      <td>...</td>\n",
              "      <td>743.772278</td>\n",
              "      <td>0.684851</td>\n",
              "      <td>2</td>\n",
              "      <td>45.233009</td>\n",
              "      <td>1.509531</td>\n",
              "      <td>10224.246094</td>\n",
              "      <td>0.173255</td>\n",
              "      <td>141.360397</td>\n",
              "      <td>1668</td>\n",
              "      <td>28.685966</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1000840</td>\n",
              "      <td>2018-01-05</td>\n",
              "      <td>-23.63</td>\n",
              "      <td>-46.58</td>\n",
              "      <td>cgs_stations</td>\n",
              "      <td>2018</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>21.909021</td>\n",
              "      <td>5</td>\n",
              "      <td>...</td>\n",
              "      <td>743.772278</td>\n",
              "      <td>0.684851</td>\n",
              "      <td>2</td>\n",
              "      <td>45.233009</td>\n",
              "      <td>1.509531</td>\n",
              "      <td>10224.246094</td>\n",
              "      <td>0.173255</td>\n",
              "      <td>141.360397</td>\n",
              "      <td>1668</td>\n",
              "      <td>28.808559</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 23 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bc04d77a-abed-4004-a387-8f90289f2066')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-bc04d77a-abed-4004-a387-8f90289f2066 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-bc04d77a-abed-4004-a387-8f90289f2066');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RFuxLZZk5yPm",
        "outputId": "42f42369-242a-48d9-d758-a2f2a2e8a741"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 18615 entries, 0 to 18614\n",
            "Data columns (total 23 columns):\n",
            " #   Column          Non-Null Count  Dtype  \n",
            "---  ------          --------------  -----  \n",
            " 0   station_code    18615 non-null  object \n",
            " 1   date            18615 non-null  object \n",
            " 2   lat             18615 non-null  float64\n",
            " 3   lon             18615 non-null  float64\n",
            " 4   source          18615 non-null  object \n",
            " 5   year            18615 non-null  int64  \n",
            " 6   month           18615 non-null  int64  \n",
            " 7   day.x           18615 non-null  int64  \n",
            " 8   temp_mean75     18316 non-null  float64\n",
            " 9   doy             18615 non-null  int64  \n",
            " 10  daylength       18615 non-null  float64\n",
            " 11  X               18615 non-null  int64  \n",
            " 12  day.y           18615 non-null  int64  \n",
            " 13  elevation_500m  18615 non-null  float64\n",
            " 14  slope_500m      18615 non-null  float64\n",
            " 15  ImprSuf_SP      18615 non-null  int64  \n",
            " 16  dist_to_coast   18615 non-null  float64\n",
            " 17  ESArivers       18615 non-null  float64\n",
            " 18  popdens         18615 non-null  float64\n",
            " 19  ndvi            18615 non-null  float64\n",
            " 20  bsa             17245 non-null  float64\n",
            " 21  sza             18615 non-null  int64  \n",
            " 22  lst             18615 non-null  float64\n",
            "dtypes: float64(12), int64(8), object(3)\n",
            "memory usage: 3.3+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Clean dataset\n",
        "df_c=df.dropna()\n",
        "df_c.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bjo9fk3QHAoz",
        "outputId": "f4849d56-ba7c-49f2-e739-642232b639ec"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 16978 entries, 0 to 18614\n",
            "Data columns (total 23 columns):\n",
            " #   Column          Non-Null Count  Dtype  \n",
            "---  ------          --------------  -----  \n",
            " 0   station_code    16978 non-null  object \n",
            " 1   date            16978 non-null  object \n",
            " 2   lat             16978 non-null  float64\n",
            " 3   lon             16978 non-null  float64\n",
            " 4   source          16978 non-null  object \n",
            " 5   year            16978 non-null  int64  \n",
            " 6   month           16978 non-null  int64  \n",
            " 7   day.x           16978 non-null  int64  \n",
            " 8   temp_mean75     16978 non-null  float64\n",
            " 9   doy             16978 non-null  int64  \n",
            " 10  daylength       16978 non-null  float64\n",
            " 11  X               16978 non-null  int64  \n",
            " 12  day.y           16978 non-null  int64  \n",
            " 13  elevation_500m  16978 non-null  float64\n",
            " 14  slope_500m      16978 non-null  float64\n",
            " 15  ImprSuf_SP      16978 non-null  int64  \n",
            " 16  dist_to_coast   16978 non-null  float64\n",
            " 17  ESArivers       16978 non-null  float64\n",
            " 18  popdens         16978 non-null  float64\n",
            " 19  ndvi            16978 non-null  float64\n",
            " 20  bsa             16978 non-null  float64\n",
            " 21  sza             16978 non-null  int64  \n",
            " 22  lst             16978 non-null  float64\n",
            "dtypes: float64(12), int64(8), object(3)\n",
            "memory usage: 3.1+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data dictionary"
      ],
      "metadata": {
        "id": "WL0yHQ-8BLgP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Below we have grouped the data in different relevant groups."
      ],
      "metadata": {
        "id": "-m-Q5TQzDA11"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "VARS = {\n",
        "    'TEMP DATA':[\n",
        "        'temp_mean75'\n",
        "    ],\n",
        "    'ATMOSPHERIC DATA': [\n",
        "       # 'bsa',\n",
        "        'sza',\n",
        "        'lst'\n",
        "    ],\n",
        "     'GEO DATA': [\n",
        "        'popdens',\n",
        "        'ESArivers',\n",
        "        'slope_500m',\n",
        "        'elevation_500m',\n",
        "        'ImprSuf_SP',\n",
        "        'dist_to_coast'\n",
        "    ],\n",
        "    'TEMPORAL DATA': [\n",
        "        'daylength'\n",
        "    ]\n",
        "}"
      ],
      "metadata": {
        "id": "gbW_z6N-BJuR"
      },
      "execution_count": 127,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data reduction and normalization"
      ],
      "metadata": {
        "id": "D_lTA8NGuo4I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Import libraries\n",
        "from sklearn.cross_decomposition import PLSRegression\n",
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "import numpy as np\n"
      ],
      "metadata": {
        "id": "oA2vm0hJwOJn"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Define functions for reducing the data:\n",
        "def pca_reducer(values, ncomponents ):\n",
        "    normalized = MinMaxScaler().fit_transform(values) #This normalizes the data\n",
        "    pca = PCA(n_components = ncomponents) #This defines data reduction\n",
        "    pca.fit(normalized.T) #This performs data reduction\n",
        "\n",
        "    return  MinMaxScaler().fit_transform(pca.components_.T)\n",
        "\n",
        "def pls_reducer(values, y, ncomponents):\n",
        "    normalized_values = MinMaxScaler().fit_transform(values) #This normalizes the data\n",
        "    X = normalized_values\n",
        "    pls = PLSRegression(n_components=ncomponents)\n",
        "    pls_score = pls.fit_transform(X, y)\n",
        "\n",
        "    return MinMaxScaler().fit_transform(pls_score[0])"
      ],
      "metadata": {
        "id": "RD1Lu-PrwTQr"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Note: based on this it’s better to set it based on the percentage we are aiming to explain and let it select the actual number of components by itself. The suggested amount is 0.95. Source:https:\\\\www.mikulskibartosz.name\\pca-how-to-choose-the-number-of-components\\\n",
        "\n",
        " "
      ],
      "metadata": {
        "id": "Dd90-3VIw2bi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The reduction and normalisation is done (a) for the response variable, in this case temperature, and (b) for all the prediction variables. The reason why we do it separetly is because the function we have defined above for the reduction embeds already the normalization. "
      ],
      "metadata": {
        "id": "p7DIXZaYDhyA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## a. Normalization for temperature variable (y)\n",
        "Here we only normalize the data, no reduction is needed as we only have one variable."
      ],
      "metadata": {
        "id": "4xyDU32GDkv8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Extract mean temperature from dataframe and apply normalization \n",
        "temp=df_c[VARS['TEMP DATA']].values\n",
        "scaler=MinMaxScaler()\n",
        "temp_data=scaler.fit_transform(temp)"
      ],
      "metadata": {
        "id": "c7uOpbDuwbqT"
      },
      "execution_count": 128,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## b. Normalization + reduction for predictor variables\n",
        "For now, we will use the PLS reduction as this not only considers the predictors but also the exposure variabel (temperature in our case). \n",
        "\n",
        "Important to remember that the n_components value should be in [1, n_features]. For example, for the atmospheric data we have 2 covariates or predictors, and so the range is [1,2] --> n_components=2"
      ],
      "metadata": {
        "id": "V3gVaRUgDppM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# We apply the funciton we defined above and we save the results by groups\n",
        "atmospheric_data= pls_reducer(df_c[VARS['ATMOSPHERIC DATA']].values, temp_data,len(VARS['ATMOSPHERIC DATA']))\n",
        "geo_data=pls_reducer(df_c[VARS['GEO DATA']].values, temp_data, len(VARS['GEO DATA']))\n",
        "temporal_data=pls_reducer(df_c[VARS['TEMPORAL DATA']].values, temp_data, len(VARS['TEMPORAL DATA']))"
      ],
      "metadata": {
        "id": "db_zL9hkDsBm"
      },
      "execution_count": 124,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data preparation"
      ],
      "metadata": {
        "id": "GAzaYva9v33w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1) Create a dataframe with the reduced/normalized data\n",
        "The normalized/reduced data we have generated above is saved as an array. Here call the array elements to save them as columns in a new pd dataframe. \n"
      ],
      "metadata": {
        "id": "QyFx_-K9K56p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "basic= {'year': df_c['year'], \n",
        "        'month': df_c['month'], \n",
        "        'day': df_c['day.x'], \n",
        "        'date': df_c['date'] }\n",
        "atmospheric = {VARS['ATMOSPHERIC DATA'][0]:atmospheric_data[:,0], \n",
        "               VARS['ATMOSPHERIC DATA'][1]:atmospheric_data[:,1]}\n",
        "geo ={VARS['GEO DATA'][0]:geo_data[:,0], \n",
        "          VARS['GEO DATA'][1]:geo_data[:,1], \n",
        "          VARS['GEO DATA'][2]:geo_data[:,2], \n",
        "          VARS['GEO DATA'][3]:geo_data[:,3],\n",
        "          VARS['GEO DATA'][4]:geo_data[:,4]}\n",
        "temporal = {VARS['TEMPORAL DATA'][0]:temporal_data[:,0]}\n",
        "temp = {VARS['TEMP DATA'][0]:temp_data[:,0]}\n",
        "\n",
        "columns={**basic, **atmospheric, **geo, **temporal, **temp}\n",
        "red_df=pd.DataFrame(columns)\n",
        "red_df.head()\n",
        "red_df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HMcgAQILLBeN",
        "outputId": "087658a7-e143-4a91-e143-831a878bc97c"
      },
      "execution_count": 150,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 16978 entries, 0 to 18614\n",
            "Data columns (total 13 columns):\n",
            " #   Column          Non-Null Count  Dtype  \n",
            "---  ------          --------------  -----  \n",
            " 0   year            16978 non-null  int64  \n",
            " 1   month           16978 non-null  int64  \n",
            " 2   day             16978 non-null  int64  \n",
            " 3   date            16978 non-null  object \n",
            " 4   sza             16978 non-null  float64\n",
            " 5   lst             16978 non-null  float64\n",
            " 6   popdens         16978 non-null  float64\n",
            " 7   ESArivers       16978 non-null  float64\n",
            " 8   slope_500m      16978 non-null  float64\n",
            " 9   elevation_500m  16978 non-null  float64\n",
            " 10  ImprSuf_SP      16978 non-null  float64\n",
            " 11  daylength       16978 non-null  float64\n",
            " 12  temp_mean75     16978 non-null  float64\n",
            "dtypes: float64(9), int64(3), object(1)\n",
            "memory usage: 1.8+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(df_c)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TZZk45qzRzzQ",
        "outputId": "4263223f-985f-46f0-be96-f11b90d5578b"
      },
      "execution_count": 148,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "16978"
            ]
          },
          "metadata": {},
          "execution_count": 148
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2) Create training and validation dataframes"
      ],
      "metadata": {
        "id": "jcclxGNxufdd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The entire underlying premise of ML is to find an algorithm that can explain as well as possible the underlying relationships between our covariates and response variable in order to produce predictions with the minimum possible error. For us to be able to test the performance of the model, we need a validation dataset. \n",
        "\n",
        "There are several ways to split the data in training and validation sets. A basic one we can start with for time series is to set aside the last couple of years of our time series or a 30% data. As a starting point, here we will use the last 100 observations (approximately 30% of 365 days)"
      ],
      "metadata": {
        "id": "fPSPNkzrOtwx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Define the date corersponding to the -30% data\n",
        "from datetime import datetime\n",
        "from datetime import timedelta\n",
        "# Subtract 10 days from a given datetime object\n",
        "dtObj = datetime.strptime(max(red_df['date']), '%Y-%m-%d')\n",
        "n = round(365*0.3)\n",
        "past_date = dtObj - timedelta(days=n)\n",
        "past_date"
      ],
      "metadata": {
        "id": "V6tZDCADuH_S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "081a92d8-f745-438a-96a5-611e94e7b41d"
      },
      "execution_count": 157,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "datetime.datetime(2018, 9, 12, 0, 0)"
            ]
          },
          "metadata": {},
          "execution_count": 157
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Create training and validation datasets\n",
        "training_df = red_df[pd.to_datetime(red_df['date']) <= past_date]\n",
        "validation_df = red_df[pd.to_datetime(red_df['date']) > past_date]"
      ],
      "metadata": {
        "id": "dgJJ24ggTB-e"
      },
      "execution_count": 163,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ATTENTION: In Alessandro's code there is an overlaping time (both datasets contain 2016). Is this done on purpose?\n",
        "\n",
        "ATTENTION 2: As we only use one year, we are loosing information on the seasonality by cutting 3 months from the time series. This will likely affect the learning and validaton. I shoudl be using 2 years minimum. "
      ],
      "metadata": {
        "id": "uXTocPN7UeJB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "training_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "v5WQROnJUk4u",
        "outputId": "43d1c680-4826-4c6a-eaaf-a969b317d4ff"
      },
      "execution_count": 164,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   year  month  day        date       sza       lst   popdens  ESArivers  \\\n",
              "0  2018      1    1  2018-01-01  0.851713  0.525190  0.799255   0.715779   \n",
              "1  2018      1    2  2018-01-02  0.852412  0.526175  0.799255   0.715779   \n",
              "2  2018      1    3  2018-01-03  0.827707  0.491383  0.799255   0.715779   \n",
              "3  2018      1    4  2018-01-04  0.836255  0.503421  0.799255   0.715779   \n",
              "4  2018      1    5  2018-01-05  0.840427  0.509297  0.799255   0.715779   \n",
              "\n",
              "   slope_500m  elevation_500m  ImprSuf_SP  daylength  temp_mean75  \n",
              "0    0.266084         0.45874    0.478603   0.990767     0.647265  \n",
              "1    0.266084         0.45874    0.478603   0.988802     0.655606  \n",
              "2    0.266084         0.45874    0.478603   0.986654     0.545117  \n",
              "3    0.266084         0.45874    0.478603   0.984323     0.534703  \n",
              "4    0.266084         0.45874    0.478603   0.981813     0.546852  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8ba50c5f-6133-4eab-b03e-5a2cbd26bee6\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>year</th>\n",
              "      <th>month</th>\n",
              "      <th>day</th>\n",
              "      <th>date</th>\n",
              "      <th>sza</th>\n",
              "      <th>lst</th>\n",
              "      <th>popdens</th>\n",
              "      <th>ESArivers</th>\n",
              "      <th>slope_500m</th>\n",
              "      <th>elevation_500m</th>\n",
              "      <th>ImprSuf_SP</th>\n",
              "      <th>daylength</th>\n",
              "      <th>temp_mean75</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2018</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2018-01-01</td>\n",
              "      <td>0.851713</td>\n",
              "      <td>0.525190</td>\n",
              "      <td>0.799255</td>\n",
              "      <td>0.715779</td>\n",
              "      <td>0.266084</td>\n",
              "      <td>0.45874</td>\n",
              "      <td>0.478603</td>\n",
              "      <td>0.990767</td>\n",
              "      <td>0.647265</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2018</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2018-01-02</td>\n",
              "      <td>0.852412</td>\n",
              "      <td>0.526175</td>\n",
              "      <td>0.799255</td>\n",
              "      <td>0.715779</td>\n",
              "      <td>0.266084</td>\n",
              "      <td>0.45874</td>\n",
              "      <td>0.478603</td>\n",
              "      <td>0.988802</td>\n",
              "      <td>0.655606</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2018</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>2018-01-03</td>\n",
              "      <td>0.827707</td>\n",
              "      <td>0.491383</td>\n",
              "      <td>0.799255</td>\n",
              "      <td>0.715779</td>\n",
              "      <td>0.266084</td>\n",
              "      <td>0.45874</td>\n",
              "      <td>0.478603</td>\n",
              "      <td>0.986654</td>\n",
              "      <td>0.545117</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2018</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>2018-01-04</td>\n",
              "      <td>0.836255</td>\n",
              "      <td>0.503421</td>\n",
              "      <td>0.799255</td>\n",
              "      <td>0.715779</td>\n",
              "      <td>0.266084</td>\n",
              "      <td>0.45874</td>\n",
              "      <td>0.478603</td>\n",
              "      <td>0.984323</td>\n",
              "      <td>0.534703</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2018</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>2018-01-05</td>\n",
              "      <td>0.840427</td>\n",
              "      <td>0.509297</td>\n",
              "      <td>0.799255</td>\n",
              "      <td>0.715779</td>\n",
              "      <td>0.266084</td>\n",
              "      <td>0.45874</td>\n",
              "      <td>0.478603</td>\n",
              "      <td>0.981813</td>\n",
              "      <td>0.546852</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8ba50c5f-6133-4eab-b03e-5a2cbd26bee6')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-8ba50c5f-6133-4eab-b03e-5a2cbd26bee6 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-8ba50c5f-6133-4eab-b03e-5a2cbd26bee6');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 164
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "validation_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "9UXf_WI8UkvS",
        "outputId": "3f69c804-bcac-49e7-bcef-f15770abe24b"
      },
      "execution_count": 165,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     year  month  day        date       sza       lst   popdens  ESArivers  \\\n",
              "255  2018      9   13  2018-09-13  0.619422  0.753333  0.799255   0.715779   \n",
              "256  2018      9   14  2018-09-14  0.634232  0.633018  0.799255   0.715779   \n",
              "257  2018      9   15  2018-09-15  0.628489  0.624929  0.799255   0.715779   \n",
              "258  2018      9   16  2018-09-16  0.614395  0.605080  0.799255   0.715779   \n",
              "259  2018      9   17  2018-09-17  0.583596  0.561705  0.799255   0.715779   \n",
              "\n",
              "     slope_500m  elevation_500m  ImprSuf_SP  daylength  temp_mean75  \n",
              "255    0.266084         0.45874    0.478603   0.413024     0.380361  \n",
              "256    0.266084         0.45874    0.478603   0.420690     0.330264  \n",
              "257    0.266084         0.45874    0.478603   0.428374     0.382199  \n",
              "258    0.266084         0.45874    0.478603   0.436073     0.330029  \n",
              "259    0.266084         0.45874    0.478603   0.443788     0.339856  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2c6c4639-8ef5-4f9f-bc7e-fa806ba5753d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>year</th>\n",
              "      <th>month</th>\n",
              "      <th>day</th>\n",
              "      <th>date</th>\n",
              "      <th>sza</th>\n",
              "      <th>lst</th>\n",
              "      <th>popdens</th>\n",
              "      <th>ESArivers</th>\n",
              "      <th>slope_500m</th>\n",
              "      <th>elevation_500m</th>\n",
              "      <th>ImprSuf_SP</th>\n",
              "      <th>daylength</th>\n",
              "      <th>temp_mean75</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>255</th>\n",
              "      <td>2018</td>\n",
              "      <td>9</td>\n",
              "      <td>13</td>\n",
              "      <td>2018-09-13</td>\n",
              "      <td>0.619422</td>\n",
              "      <td>0.753333</td>\n",
              "      <td>0.799255</td>\n",
              "      <td>0.715779</td>\n",
              "      <td>0.266084</td>\n",
              "      <td>0.45874</td>\n",
              "      <td>0.478603</td>\n",
              "      <td>0.413024</td>\n",
              "      <td>0.380361</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>256</th>\n",
              "      <td>2018</td>\n",
              "      <td>9</td>\n",
              "      <td>14</td>\n",
              "      <td>2018-09-14</td>\n",
              "      <td>0.634232</td>\n",
              "      <td>0.633018</td>\n",
              "      <td>0.799255</td>\n",
              "      <td>0.715779</td>\n",
              "      <td>0.266084</td>\n",
              "      <td>0.45874</td>\n",
              "      <td>0.478603</td>\n",
              "      <td>0.420690</td>\n",
              "      <td>0.330264</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>257</th>\n",
              "      <td>2018</td>\n",
              "      <td>9</td>\n",
              "      <td>15</td>\n",
              "      <td>2018-09-15</td>\n",
              "      <td>0.628489</td>\n",
              "      <td>0.624929</td>\n",
              "      <td>0.799255</td>\n",
              "      <td>0.715779</td>\n",
              "      <td>0.266084</td>\n",
              "      <td>0.45874</td>\n",
              "      <td>0.478603</td>\n",
              "      <td>0.428374</td>\n",
              "      <td>0.382199</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>258</th>\n",
              "      <td>2018</td>\n",
              "      <td>9</td>\n",
              "      <td>16</td>\n",
              "      <td>2018-09-16</td>\n",
              "      <td>0.614395</td>\n",
              "      <td>0.605080</td>\n",
              "      <td>0.799255</td>\n",
              "      <td>0.715779</td>\n",
              "      <td>0.266084</td>\n",
              "      <td>0.45874</td>\n",
              "      <td>0.478603</td>\n",
              "      <td>0.436073</td>\n",
              "      <td>0.330029</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>259</th>\n",
              "      <td>2018</td>\n",
              "      <td>9</td>\n",
              "      <td>17</td>\n",
              "      <td>2018-09-17</td>\n",
              "      <td>0.583596</td>\n",
              "      <td>0.561705</td>\n",
              "      <td>0.799255</td>\n",
              "      <td>0.715779</td>\n",
              "      <td>0.266084</td>\n",
              "      <td>0.45874</td>\n",
              "      <td>0.478603</td>\n",
              "      <td>0.443788</td>\n",
              "      <td>0.339856</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2c6c4639-8ef5-4f9f-bc7e-fa806ba5753d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2c6c4639-8ef5-4f9f-bc7e-fa806ba5753d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2c6c4639-8ef5-4f9f-bc7e-fa806ba5753d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 165
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define data handling functions (copied from Alessandro)\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "class datasetHandler:\n",
        "\n",
        "    def __init__(self, train_dataframe, val_dataframe):\n",
        "        self.training = train_dataframe\n",
        "        self.validation = val_dataframe\n",
        "\n",
        "    def get_data(self, t_window_size, t_prediction):\n",
        "\n",
        "        # Get the first department to asses data dimensions\n",
        "        departments = pd.unique(self.training.dep_id)\n",
        "        db_dep = self.training[self.training.dep_id == departments[0]]\n",
        "        # len_series = db_dep.shape[0] - (t_window_size + t_prediction)\n",
        "        len_series = db_dep.shape[0] - (t_window_size)\n",
        "\n",
        "        # Initialize training dataset\n",
        "        x_train = np.zeros((len_series*len(departments), t_window_size, self.training.shape[1]))\n",
        "        y_train = np.zeros((len_series*len(departments), 2*t_prediction))\n",
        "        print('X Training shape', x_train.shape)\n",
        "        print('Y Training shape', x_train.shape)\n",
        "\n",
        "        # Fill the training set\n",
        "        counter = 0\n",
        "        for count, dep in enumerate(departments):\n",
        "            db_dep = self.training[self.training.dep_id == dep]\n",
        "            data = db_dep.to_numpy()\n",
        "\n",
        "            print('\\rProcessing departments {} of {}'.format(count, len(departments)), end='\\t\\t')\n",
        "\n",
        "            for count2 in range(len_series):\n",
        "                x_train[counter, ...] = data[count2 : (count2)+t_window_size, :]\n",
        "                y_train[counter, ..., :t_prediction] = data[(count2 + t_window_size) : (count2 + t_window_size + t_prediction), -2]\n",
        "                y_train[counter, ..., t_prediction:] = data[(count2 + t_window_size) : (count2 + t_window_size + t_prediction), -1]\n",
        "                counter+=1\n",
        "\n",
        "        #  Get the first department to asses data dimensions\n",
        "        departments = pd.unique(self.validation.dep_id)\n",
        "        db_dep = self.validation[self.validation.dep_id == departments[0]]\n",
        "        # len_series  = db_dep.shape[0] - (t_window_size + t_prediction)\n",
        "        len_series = db_dep.shape[0] - (t_window_size)\n",
        "        \n",
        "        # Initialize validation dataset\n",
        "        x_val = np.zeros((len_series*len(departments), t_window_size, self.validation.shape[1]))\n",
        "        y_val = np.zeros((len_series*len(departments), 2*t_prediction))\n",
        "        print('\\nX Validation shape', x_val.shape)\n",
        "        print('Y Validation shape', y_val.shape)\n",
        "\n",
        "        counter = 0\n",
        "        # Fill the validation set\n",
        "        for count, dep in enumerate(departments):\n",
        "            db_dep = self.validation[self.validation.dep_id == dep]\n",
        "            data = db_dep.to_numpy()\n",
        "\n",
        "            print('\\rProcessing departments {} of {}'.format(count, len(departments)), end='\\t\\t')\n",
        "\n",
        "            for count2 in range(len_series):\n",
        "                x_val[counter, ...] = data[count2 : (count2)+t_window_size, :]\n",
        "                y_val[counter, ..., :t_prediction] = data[count2 + t_window_size:count2 + t_window_size + t_prediction, -2]\n",
        "                y_val[counter, ..., t_prediction:] = data[count2 + t_window_size:count2 + t_window_size + t_prediction, -1]\n",
        "                counter += 1\n",
        "\n",
        "        return x_train, y_train, x_val, y_val\n",
        "\n",
        "    def augment(self, x_train, y_train, x_val, y_val, multiplier = 3):\n",
        "        x_train_a = np.zeros((multiplier*x_train.shape[0], x_train.shape[1], x_train.shape[2]))\n",
        "        y_train_a = np.zeros((multiplier*y_train.shape[0], y_train.shape[1]))\n",
        "        x_val_a   = np.zeros((multiplier*x_val.shape[0],   x_val.shape[1],   x_val.shape[2]))\n",
        "        y_val_a   = np.zeros((multiplier*y_val.shape[0],   y_val.shape[1]))\n",
        "\n",
        "        for i in range(multiplier):\n",
        "            x_train_a[i*x_train.shape[0]:(i+1)*x_train.shape[0], ...] = x_train + np.random.normal(0, 0.01, size =x_train.shape[0]*x_train.shape[1]*x_train.shape[2]).reshape(x_train.shape[0],x_train.shape[1],x_train.shape[2])\n",
        "            x_val_a[i*x_val.shape[0]:(i+1)*x_val.shape[0], ...] = x_val + np.random.normal(0, 0.01, size =x_val.shape[0]*x_val.shape[1]*x_val.shape[2]).reshape(x_val.shape[0],x_val.shape[1],x_val.shape[2])\n",
        "            y_train_a[i*y_train.shape[0]:(i+1)*y_train.shape[0], ...] = y_train\n",
        "            y_val_a[i*y_val.shape[0]:(i+1)*y_val.shape[0], ...] = y_val\n",
        "\n",
        "        return x_train_a, y_train_a, x_val_a, y_val_a\n",
        "\n",
        "    def prepare_data_LSTM(self, x_train, y_train, x_val, y_val):\n",
        "        return (x_train, y_train), (x_val, y_val)\n",
        "\n",
        "    def prepare_data_CatBoost(self, x_train, y_train, x_val, y_val):\n",
        "        x_train = x_train.reshape((x_train.shape[0], x_train.shape[1]*x_train.shape[2]))\n",
        "        x_val   =   x_val.reshape((x_val.shape[0],   x_val.shape[1]*x_val.shape[2]))\n",
        "        return (x_train, y_train), (x_val, y_val)"
      ],
      "metadata": {
        "id": "_JccZbXaWpuK"
      },
      "execution_count": 168,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import datasetHandler\n",
        "dataset_handler = datasetHandler(training_df, validation_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "id": "W7f_RlwqW2Nm",
        "outputId": "45202883-3a15-47b6-b9b8-8b4573c99b5a"
      },
      "execution_count": 170,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-170-71c6978f5c3b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mdatasetHandler\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdataset_handler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatasetHandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'datasetHandler'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    }
  ]
}